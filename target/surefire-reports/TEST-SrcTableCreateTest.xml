<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="SrcTableCreateTest" time="15.281" tests="1" errors="0" skipped="0" failures="1">
  <properties>
    <property name="java.runtime.name" value="Java(TM) SE Runtime Environment"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-oracle/jre/lib/amd64"/>
    <property name="java.vm.version" value="25.181-b13"/>
    <property name="java.vm.vendor" value="Oracle Corporation"/>
    <property name="maven.multiModuleProjectDirectory" value="/home/aman/Desktop/Workspace/HiveUnitTests"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="path.separator" value=":"/>
    <property name="guice.disable.misplaced.annotation.check" value="true"/>
    <property name="java.vm.name" value="Java HotSpot(TM) 64-Bit Server VM"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="user.country" value="IN"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.dir" value="/home/aman/Desktop/Workspace/HiveUnitTests"/>
    <property name="java.runtime.version" value="1.8.0_181-b13"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-oracle/jre/lib/endorsed"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="os.name" value="Linux"/>
    <property name="classworlds.conf" value="/usr/share/maven/bin/m2.conf"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="maven.conf" value="/usr/share/maven/conf"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.class.version" value="52.0"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="os.version" value="4.15.0-30-generic"/>
    <property name="library.jansi.path" value="/usr/share/maven/lib/jansi-native"/>
    <property name="user.home" value="/home/aman"/>
    <property name="user.timezone" value="Asia/Kolkata"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="hive.metastore.warehouse.dir" value="/tmp/foo"/>
    <property name="user.name" value="aman"/>
    <property name="java.class.path" value="/usr/share/maven/boot/plexus-classworlds-2.x.jar"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-oracle/jre"/>
    <property name="sun.java.command" value="org.codehaus.plexus.classworlds.launcher.Launcher clean test -Dhive.metastore.warehouse.dir=/tmp/foo"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="user.language" value="en"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.version" value="1.8.0_181"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-oracle/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="securerandom.source" value="file:/dev/./urandom"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-oracle/jre/lib/resources.jar:/usr/lib/jvm/java-8-oracle/jre/lib/rt.jar:/usr/lib/jvm/java-8-oracle/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-oracle/jre/lib/jsse.jar:/usr/lib/jvm/java-8-oracle/jre/lib/jce.jar:/usr/lib/jvm/java-8-oracle/jre/lib/charsets.jar:/usr/lib/jvm/java-8-oracle/jre/lib/jfr.jar:/usr/lib/jvm/java-8-oracle/jre/classes"/>
    <property name="java.vendor" value="Oracle Corporation"/>
    <property name="maven.home" value="/usr/share/maven"/>
    <property name="file.separator" value="/"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="sun.desktop" value="gnome"/>
    <property name="sun.cpu.isalist" value=""/>
  </properties>
  <testcase name="testDelimiter" classname="SrcTableCreateTest" time="15.281">
    <failure message="expected:&lt;1&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.junit.Assert.assertEquals(Assert.java:456)
	at SrcTableCreateTest.testDelimiter(SrcTableCreateTest.java:50)
]]></failure>
    <system-err><![CDATA[Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/08/23 13:57:34 INFO SparkContext: Running Spark version 1.4.1
18/08/23 13:57:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/08/23 13:57:34 WARN Utils: Your hostname, aman-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
18/08/23 13:57:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/08/23 13:57:34 INFO SecurityManager: Changing view acls to: aman
18/08/23 13:57:34 INFO SecurityManager: Changing modify acls to: aman
18/08/23 13:57:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(aman); users with modify permissions: Set(aman)
18/08/23 13:57:36 INFO Slf4jLogger: Slf4jLogger started
18/08/23 13:57:36 INFO Remoting: Starting remoting
18/08/23 13:57:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.2.15:39315]
18/08/23 13:57:36 INFO Utils: Successfully started service 'sparkDriver' on port 39315.
18/08/23 13:57:36 INFO SparkEnv: Registering MapOutputTracker
18/08/23 13:57:36 INFO SparkEnv: Registering BlockManagerMaster
18/08/23 13:57:36 INFO DiskBlockManager: Created local directory at /tmp/spark-05a01ec4-c909-4bf9-934f-263e8c1afd35/blockmgr-81f69351-e849-49c3-aa4e-3ca2984976af
18/08/23 13:57:36 INFO MemoryStore: MemoryStore started with capacity 867.6 MB
18/08/23 13:57:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-05a01ec4-c909-4bf9-934f-263e8c1afd35/httpd-a8465944-1cf2-4334-ba44-8595e22ee86c
18/08/23 13:57:37 INFO HttpServer: Starting HTTP Server
18/08/23 13:57:37 INFO Utils: Successfully started service 'HTTP file server' on port 43567.
18/08/23 13:57:37 INFO SparkEnv: Registering OutputCommitCoordinator
18/08/23 13:57:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/08/23 13:57:37 INFO SparkUI: Started SparkUI at http://10.0.2.15:4040
18/08/23 13:57:37 INFO Executor: Starting executor ID driver on host localhost
18/08/23 13:57:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43483.
18/08/23 13:57:38 INFO NettyBlockTransferService: Server created on 43483
18/08/23 13:57:38 INFO BlockManagerMaster: Trying to register BlockManager
18/08/23 13:57:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43483 with 867.6 MB RAM, BlockManagerId(driver, localhost, 43483)
18/08/23 13:57:38 INFO BlockManagerMaster: Registered BlockManager
18/08/23 13:57:40 INFO HiveContext: Initializing execution hive, version 0.13.1
18/08/23 13:57:40 INFO deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
18/08/23 13:57:40 INFO deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
18/08/23 13:57:40 INFO deprecation: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
18/08/23 13:57:40 INFO deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
18/08/23 13:57:40 INFO deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
18/08/23 13:57:40 INFO deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
18/08/23 13:57:40 INFO deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
18/08/23 13:57:40 INFO deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
18/08/23 13:57:40 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/08/23 13:57:40 INFO ObjectStore: ObjectStore, initialize called
18/08/23 13:57:41 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/08/23 13:57:41 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/08/23 13:57:44 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/08/23 13:57:44 INFO MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: Lexical error at line 1, column 5.  Encountered: "@" (64), after : "".
18/08/23 13:57:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:57:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:57:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:57:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:57:49 INFO ObjectStore: Initialized ObjectStore
18/08/23 13:57:49 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.13.1aa
18/08/23 13:57:50 INFO HiveMetaStore: Added admin role in metastore
18/08/23 13:57:50 INFO HiveMetaStore: Added public role in metastore
18/08/23 13:57:50 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/08/23 13:57:50 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.
18/08/23 13:57:50 INFO ParseDriver: Parsing command: CREATE TABLE IF NOT EXISTS src (columnOne String, columnTwo String)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|' ESCAPED BY '\\'
NULL DEFINED AS ''
18/08/23 13:57:51 INFO ParseDriver: Parse Completed
18/08/23 13:57:51 INFO HiveContext: Initializing HiveMetastoreConnection version 0.13.1 using Spark classes.
18/08/23 13:57:51 INFO deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
18/08/23 13:57:51 INFO deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
18/08/23 13:57:51 INFO deprecation: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
18/08/23 13:57:51 INFO deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
18/08/23 13:57:51 INFO deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
18/08/23 13:57:51 INFO deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
18/08/23 13:57:51 INFO deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
18/08/23 13:57:51 INFO deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
18/08/23 13:57:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/08/23 13:57:52 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/08/23 13:57:52 INFO ObjectStore: ObjectStore, initialize called
18/08/23 13:57:52 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/08/23 13:57:52 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/08/23 13:57:54 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/08/23 13:57:54 INFO MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: Lexical error at line 1, column 5.  Encountered: "@" (64), after : "".
18/08/23 13:57:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:57:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:57:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:57:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:57:56 INFO Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
18/08/23 13:57:56 INFO ObjectStore: Initialized ObjectStore
18/08/23 13:57:57 INFO HiveMetaStore: Added admin role in metastore
18/08/23 13:57:57 INFO HiveMetaStore: Added public role in metastore
18/08/23 13:57:57 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/08/23 13:57:57 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.
18/08/23 13:57:58 INFO PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:58 INFO PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:58 INFO Driver: Concurrency mode is disabled, not creating a lock manager
18/08/23 13:57:58 INFO PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:58 INFO PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:58 INFO ParseDriver: Parsing command: CREATE TABLE IF NOT EXISTS src (columnOne String, columnTwo String)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|' ESCAPED BY '\\'
NULL DEFINED AS ''
18/08/23 13:57:58 INFO ParseDriver: Parse Completed
18/08/23 13:57:58 INFO PerfLogger: </PERFLOG method=parse start=1535012878239 end=1535012878658 duration=419 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:58 INFO PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:58 INFO SemanticAnalyzer: Starting Semantic Analysis
18/08/23 13:57:58 INFO SemanticAnalyzer: Creating table src position=27
18/08/23 13:57:58 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:57:58 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:57:59 INFO HiveMetaStore: 0: get_database: default
18/08/23 13:57:59 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_database: default	
18/08/23 13:57:59 INFO Driver: Semantic Analysis Completed
18/08/23 13:57:59 INFO PerfLogger: </PERFLOG method=semanticAnalyze start=1535012878660 end=1535012879159 duration=499 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:59 INFO Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
18/08/23 13:57:59 INFO PerfLogger: </PERFLOG method=compile start=1535012878175 end=1535012879175 duration=1000 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:59 INFO PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:59 INFO Driver: Starting command: CREATE TABLE IF NOT EXISTS src (columnOne String, columnTwo String)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|' ESCAPED BY '\\'
NULL DEFINED AS ''
18/08/23 13:57:59 INFO PerfLogger: </PERFLOG method=TimeToSubmit start=1535012878168 end=1535012879188 duration=1020 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:59 INFO PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:59 INFO PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:57:59 INFO DDLTask: Default to LazySimpleSerDe for table src
18/08/23 13:57:59 INFO HiveMetaStore: 0: create_table: Table(tableName:src, dbName:default, owner:aman, createTime:1535012879, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:columnone, type:string, comment:null), FieldSchema(name:columntwo, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{escape.delim=\, field.delim=|, serialization.format=|, serialization.null.format=}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)
18/08/23 13:57:59 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=create_table: Table(tableName:src, dbName:default, owner:aman, createTime:1535012879, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:columnone, type:string, comment:null), FieldSchema(name:columntwo, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{escape.delim=\, field.delim=|, serialization.format=|, serialization.null.format=}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)	
18/08/23 13:58:00 INFO PerfLogger: </PERFLOG method=runTasks start=1535012879190 end=1535012880106 duration=916 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO PerfLogger: </PERFLOG method=Driver.execute start=1535012879175 end=1535012880109 duration=934 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO Driver: OK
18/08/23 13:58:00 INFO PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO PerfLogger: </PERFLOG method=releaseLocks start=1535012880115 end=1535012880115 duration=0 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO PerfLogger: </PERFLOG method=Driver.run start=1535012878167 end=1535012880115 duration=1948 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO ParseDriver: Parsing command: LOAD DATA LOCAL INPATH '/tmp/junit5469477455640742318/src.dat' INTO TABLE src
18/08/23 13:58:00 INFO ParseDriver: Parse Completed
18/08/23 13:58:00 INFO PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO Driver: Concurrency mode is disabled, not creating a lock manager
18/08/23 13:58:00 INFO PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO ParseDriver: Parsing command: LOAD DATA LOCAL INPATH '/tmp/junit5469477455640742318/src.dat' INTO TABLE src
18/08/23 13:58:00 INFO ParseDriver: Parse Completed
18/08/23 13:58:00 INFO PerfLogger: </PERFLOG method=parse start=1535012880374 end=1535012880380 duration=6 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:00 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:00 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:01 INFO Driver: Semantic Analysis Completed
18/08/23 13:58:01 INFO PerfLogger: </PERFLOG method=semanticAnalyze start=1535012880380 end=1535012881011 duration=631 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:01 INFO Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
18/08/23 13:58:01 INFO PerfLogger: </PERFLOG method=compile start=1535012880374 end=1535012881021 duration=647 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:01 INFO PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:01 INFO Driver: Starting command: LOAD DATA LOCAL INPATH '/tmp/junit5469477455640742318/src.dat' INTO TABLE src
18/08/23 13:58:01 INFO PerfLogger: </PERFLOG method=TimeToSubmit start=1535012880374 end=1535012881023 duration=649 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:01 INFO PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:01 INFO PerfLogger: <PERFLOG method=task.COPY.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:01 INFO Task: Copying data from file:/tmp/junit5469477455640742318/src.dat to file:/tmp/hive-aman/hive_2018-08-23_13-58-00_374_3308793426360188495-1/-ext-10000
18/08/23 13:58:01 INFO Task: Copying file: file:/tmp/junit5469477455640742318/src.dat
18/08/23 13:58:01 INFO PerfLogger: <PERFLOG method=task.MOVE.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:01 INFO Task: Loading data to table default.src from file:/tmp/hive-aman/hive_2018-08-23_13-58-00_374_3308793426360188495-1/-ext-10000
18/08/23 13:58:01 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:01 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:01 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:01 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:01 INFO Hive: Renaming src:file:/tmp/hive-aman/hive_2018-08-23_13-58-00_374_3308793426360188495-1/-ext-10000/src.dat;dest: file:/tmp/foo/src/src.dat;Status:true
18/08/23 13:58:01 INFO HiveMetaStore: 0: alter_table: db=default tbl=src newtbl=src
18/08/23 13:58:01 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=src newtbl=src	
18/08/23 13:58:01 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:01 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:01 INFO log: Updating table stats fast for src
18/08/23 13:58:01 INFO log: Updated size of table src to 0
18/08/23 13:58:01 INFO PerfLogger: <PERFLOG method=task.STATS.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:01 INFO StatsTask: Executing stats task
18/08/23 13:58:01 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:01 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:01 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:01 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:01 INFO HiveMetaStore: 0: alter_table: db=default tbl=src newtbl=src
18/08/23 13:58:01 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=src newtbl=src	
18/08/23 13:58:01 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:01 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:01 INFO log: Updating table stats fast for src
18/08/23 13:58:01 INFO log: Updated size of table src to 0
18/08/23 13:58:02 INFO Task: Table default.src stats: [numFiles=1, numRows=0, totalSize=0, rawDataSize=0]
18/08/23 13:58:02 INFO PerfLogger: </PERFLOG method=runTasks start=1535012881025 end=1535012882038 duration=1013 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:02 INFO PerfLogger: </PERFLOG method=Driver.execute start=1535012881022 end=1535012882044 duration=1022 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:02 INFO Driver: OK
18/08/23 13:58:02 INFO PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:02 INFO PerfLogger: </PERFLOG method=releaseLocks start=1535012882044 end=1535012882044 duration=0 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:02 INFO PerfLogger: </PERFLOG method=Driver.run start=1535012880368 end=1535012882045 duration=1677 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:02 INFO ParseDriver: Parsing command: SELECT columnOne from src
18/08/23 13:58:02 INFO ParseDriver: Parse Completed
18/08/23 13:58:02 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:02 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:02 INFO MemoryStore: ensureFreeSpace(396952) called with curMem=0, maxMem=909720944
18/08/23 13:58:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 387.6 KB, free 867.2 MB)
18/08/23 13:58:02 INFO MemoryStore: ensureFreeSpace(29623) called with curMem=396952, maxMem=909720944
18/08/23 13:58:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.9 KB, free 867.2 MB)
18/08/23 13:58:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43483 (size: 28.9 KB, free: 867.5 MB)
18/08/23 13:58:02 INFO SparkContext: Created broadcast 0 from collect at SrcTableCreateTest.java:48
18/08/23 13:58:03 INFO FileInputFormat: Total input paths to process : 1
18/08/23 13:58:03 INFO SparkContext: Starting job: collect at SrcTableCreateTest.java:48
18/08/23 13:58:03 INFO DAGScheduler: Got job 0 (collect at SrcTableCreateTest.java:48) with 1 output partitions (allowLocal=false)
18/08/23 13:58:03 INFO DAGScheduler: Final stage: ResultStage 0(collect at SrcTableCreateTest.java:48)
18/08/23 13:58:03 INFO DAGScheduler: Parents of final stage: List()
18/08/23 13:58:03 INFO DAGScheduler: Missing parents: List()
18/08/23 13:58:03 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at collect at SrcTableCreateTest.java:48), which has no missing parents
18/08/23 13:58:03 INFO MemoryStore: ensureFreeSpace(8216) called with curMem=426575, maxMem=909720944
18/08/23 13:58:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.0 KB, free 867.2 MB)
18/08/23 13:58:03 INFO MemoryStore: ensureFreeSpace(4479) called with curMem=434791, maxMem=909720944
18/08/23 13:58:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 867.2 MB)
18/08/23 13:58:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43483 (size: 4.4 KB, free: 867.5 MB)
18/08/23 13:58:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:874
18/08/23 13:58:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at collect at SrcTableCreateTest.java:48)
18/08/23 13:58:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/08/23 13:58:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1398 bytes)
18/08/23 13:58:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/08/23 13:58:03 INFO HadoopRDD: Input split: file:/tmp/foo/src/src.dat:0+0
18/08/23 13:58:03 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
18/08/23 13:58:03 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
18/08/23 13:58:03 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
18/08/23 13:58:03 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
18/08/23 13:58:03 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
18/08/23 13:58:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1800 bytes result sent to driver
18/08/23 13:58:04 INFO DAGScheduler: ResultStage 0 (collect at SrcTableCreateTest.java:48) finished in 0.368 s
18/08/23 13:58:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 342 ms on localhost (1/1)
18/08/23 13:58:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/08/23 13:58:04 INFO DAGScheduler: Job 0 finished: collect at SrcTableCreateTest.java:48, took 0.667921 s
18/08/23 13:58:04 INFO ParseDriver: Parsing command: DROP TABLE IF EXISTS src
18/08/23 13:58:04 INFO ParseDriver: Parse Completed
18/08/23 13:58:04 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:04 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:04 INFO PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO Driver: Concurrency mode is disabled, not creating a lock manager
18/08/23 13:58:04 INFO PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO ParseDriver: Parsing command: DROP TABLE IF EXISTS src
18/08/23 13:58:04 INFO ParseDriver: Parse Completed
18/08/23 13:58:04 INFO PerfLogger: </PERFLOG method=parse start=1535012884235 end=1535012884250 duration=15 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:04 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:04 INFO Driver: Semantic Analysis Completed
18/08/23 13:58:04 INFO PerfLogger: </PERFLOG method=semanticAnalyze start=1535012884250 end=1535012884322 duration=72 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
18/08/23 13:58:04 INFO PerfLogger: </PERFLOG method=compile start=1535012884235 end=1535012884323 duration=88 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO Driver: Starting command: DROP TABLE IF EXISTS src
18/08/23 13:58:04 INFO PerfLogger: </PERFLOG method=TimeToSubmit start=1535012884234 end=1535012884329 duration=95 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:04 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:04 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:04 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:04 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:04 INFO HiveMetaStore: 0: drop_table : db=default tbl=src
18/08/23 13:58:04 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=src	
18/08/23 13:58:04 INFO HiveMetaStore: 0: get_table : db=default tbl=src
18/08/23 13:58:04 INFO audit: ugi=aman	ip=unknown-ip-addr	cmd=get_table : db=default tbl=src	
18/08/23 13:58:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:43483 in memory (size: 4.4 KB, free: 867.5 MB)
18/08/23 13:58:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/08/23 13:58:05 INFO hivemetastoressimpl: deleting  file:/tmp/foo/src
18/08/23 13:58:05 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
18/08/23 13:58:05 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
18/08/23 13:58:05 INFO hivemetastoressimpl: Deleted the diretory file:/tmp/foo/src
18/08/23 13:58:05 INFO PerfLogger: </PERFLOG method=runTasks start=1535012884329 end=1535012885813 duration=1484 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:05 INFO PerfLogger: </PERFLOG method=Driver.execute start=1535012884324 end=1535012885816 duration=1492 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:05 INFO Driver: OK
18/08/23 13:58:05 INFO PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:05 INFO PerfLogger: </PERFLOG method=releaseLocks start=1535012885818 end=1535012885818 duration=0 from=org.apache.hadoop.hive.ql.Driver>
18/08/23 13:58:05 INFO PerfLogger: </PERFLOG method=Driver.run start=1535012884230 end=1535012885819 duration=1589 from=org.apache.hadoop.hive.ql.Driver>
]]></system-err>
  </testcase>
</testsuite>